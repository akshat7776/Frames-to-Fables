{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "05373b1b-ef95-449c-89c7-40069b5588ea",
      "metadata": {
        "id": "05373b1b-ef95-449c-89c7-40069b5588ea"
      },
      "source": [
        "# Assignment 4: Text Classification on TREC dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d2ad257-ec97-47bd-8cca-a2655fa5d92e",
      "metadata": {
        "id": "1d2ad257-ec97-47bd-8cca-a2655fa5d92e"
      },
      "source": [
        "We are going to use the TREC dataset for this assignment, which is widely considered a benchmark text classification dataset. Read about the TREC dataset here (https://huggingface.co/datasets/CogComp/trec), also google it for understanding it better.\n",
        "\n",
        "This is what you have to do - use the concepts we have covered so far to accurately predict the 5 coarse labels (if you have googled TERC, you will surely know what I mean) in the test dataset. Train on the train dataset and give results on the test dataset, as simple as that. And experiment, experiment and experiment!\n",
        "\n",
        "Your experimentation should be 4-tiered-\n",
        "\n",
        "i) Experiment with preprocessing techniques (different types of Stemming, Lemmatizing, or do neither and keep the words pure). Needless to say, certain things, like stopword removal, should be common in all the preprocesssing pipelines you come up with. Remember never do stemming and lemmatization together. Note - To find out the best preprocessing technique, use a simple baseline model, like say CountVectorizer(BoW) + Logistic Regression, and see which gives the best accuracy. Then proceed with that preprocessing technique only for all the other models.\n",
        "\n",
        "ii) Try out various vectorisation techniques (BoW, TF-IDF, CBoW, Skipgram, GloVE, Fasttext, etc., but transformer models are not allowed) -- Atleast 5 different types\n",
        "\n",
        "iii) Tinker with various strategies to combine the word vectors (taking mean, using RNN/LSTM, and the other strategies I hinted at in the end of the last sesion). Note that this is applicable only for the advanced embedding techniques which generate word embeddings. -- Atleast 3 different types, one of which should definitely be RNN/LSTM\n",
        "\n",
        "iv) Finally, experiment with the ML classifier model, which will take the final vector respresentation of each TREC question and generate the label. E.g. - Logistic regression, decision trees, simple neural network, etc. - Atleast 4 different models\n",
        "\n",
        "So applying some PnC, in total you should get more than 40 different combinations. Print out the accuracies of all these combinations nicely in a well-formatted table, and pronounce one of them the best. Also feel free to experiment with more models/embedding techniques than what I have said here, the goal is after all to achieve the highest accuracy, as long as you don't use transformers. Happy experimenting!\n",
        "\n",
        "NOTE - While choosing the 4-5 types of each experimentation level, try to choose the best out of all those available. E.g. - For level (iii) - Tinker with various strategies to combine the word vectors - do not include 'mean' if you see it is giving horrendous results. Include the best 3-4 strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cca5a12-6ddf-4895-a962-fd8fac4ad1f9",
      "metadata": {
        "id": "0cca5a12-6ddf-4895-a962-fd8fac4ad1f9"
      },
      "source": [
        "### Helper Code to get you started"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54d08592-c633-4764-a60a-4937fd768cb4",
      "metadata": {
        "id": "54d08592-c633-4764-a60a-4937fd768cb4"
      },
      "source": [
        "I have added some helper code to show you how to load the TERC dataset and use it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U fsspec\n",
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5_acm45sfe4L",
        "outputId": "ad80b163-b5aa-4ed8-c568-f6e3c2feffea"
      },
      "id": "5_acm45sfe4L",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.5.1\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.1\n",
            "    Uninstalling fsspec-2025.5.1:\n",
            "      Successfully uninstalled fsspec-2025.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"trec\")\n",
        "train_data = dataset['train']\n",
        "test_data = dataset['test']\n",
        "\n",
        "print(\"Sample Question:\", train_data[0]['text'])\n",
        "print(\"Label:\", train_data[0]['coarse_label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg9ZLyWGf0_a",
        "outputId": "3a9ede82-1f5a-4891-b31a-ed1644631a12"
      },
      "id": "Dg9ZLyWGf0_a",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Question: How did serfdom develop in and then leave Russia ?\n",
            "Label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UZyeHNigF8q",
        "outputId": "0eac98d9-d5f7-4171-cb35-4f8f7d8bfd7d"
      },
      "id": "7UZyeHNigF8q",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer(\"english\")\n",
        "\n",
        "def preprocess(text, mode=\"pure\"):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    if mode == \"porter\":\n",
        "        tokens = [porter.stem(word) for word in tokens]\n",
        "    elif mode == \"snowball\":\n",
        "        tokens = [snowball.stem(word) for word in tokens]\n",
        "    elif mode == \"lemma\":\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "FJC4TgiUgeWF"
      },
      "id": "FJC4TgiUgeWF",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_raw = [x['text'] for x in train_data]\n",
        "y_train = [x['coarse_label'] for x in train_data]\n",
        "x_test_raw = [x['text'] for x in test_data]\n",
        "y_test = [x['coarse_label'] for x in test_data]\n",
        "\n",
        "results = []\n",
        "\n",
        "for mode in [\"pure\", \"porter\", \"snowball\", \"lemma\"]:\n",
        "\n",
        "    x_train = [preprocess(text, mode) for text in x_train_raw]\n",
        "    x_test = [preprocess(text, mode) for text in x_test_raw]\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "    x_train_vec = vectorizer.fit_transform(x_train)\n",
        "    x_test_vec = vectorizer.transform(x_test)\n",
        "\n",
        "    clf = LogisticRegression(max_iter=300)\n",
        "    clf.fit(x_train_vec, y_train)\n",
        "    y_pred = clf.predict(x_test_vec)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results.append((mode, acc))\n",
        "\n",
        "df_results = pd.DataFrame(results, columns=[\"Preprocessing\", \"Accuracy\"])\n",
        "df_results = df_results.sort_values(\"Accuracy\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELKkqoswiC9v",
        "outputId": "5ae7efa9-7e3a-4f26-b4c0-27ed31406da7"
      },
      "id": "ELKkqoswiC9v",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preprocessing  Accuracy\n",
            "0         lemma     0.756\n",
            "1      snowball     0.756\n",
            "2        porter     0.754\n",
            "3          pure     0.752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use lemmatization further"
      ],
      "metadata": {
        "id": "LfnVaM1FkoeY"
      },
      "id": "LfnVaM1FkoeY"
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "x_train = [preprocess(text, 'lemm') for text in x_train_raw]\n",
        "x_test = [preprocess(text, 'lemm') for text in x_test_raw]\n",
        "\n",
        "x_train_tok = [text.split() for text in x_train]\n",
        "x_test_tok = [text.split() for text in x_test]\n",
        "\n",
        "vectorized_data = {}\n",
        "\n",
        "vectorizer_bow = CountVectorizer()\n",
        "x_train_bow = vectorizer_bow.fit_transform(x_train)\n",
        "x_test_bow = vectorizer_bow.transform(x_test)\n",
        "vectorized_data['BoW'] = (x_train_bow, x_test_bow)\n",
        "\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "x_train_tfidf = vectorizer_tfidf.fit_transform(x_train)\n",
        "x_test_tfidf = vectorizer_tfidf.transform(x_test)\n",
        "vectorized_data['TF-IDF'] = (x_train_tfidf, x_test_tfidf)\n",
        "\n",
        "w2v_cbow = api.load(\"word2vec-google-news-300\")\n",
        "glove = api.load(\"glove-wiki-gigaword-300\")\n",
        "fasttext = api.load(\"fasttext-wiki-news-subwords-300\")\n",
        "w2v_skipgram = api.load(\"word2vec-ruscorpora-300\")\n",
        "\n",
        "def average_word_vectors(tokens_list, model, dim=300):\n",
        "    vectors = []\n",
        "    for tokens in tokens_list:\n",
        "        vecs = [model[word] for word in tokens if word in model]\n",
        "        if vecs:\n",
        "            vectors.append(np.mean(vecs, axis=0))\n",
        "        else:\n",
        "            vectors.append(np.zeros(dim))\n",
        "    return np.array(vectors)\n",
        "\n",
        "x_train_cbow = average_word_vectors(x_train_tok, w2v_cbow)\n",
        "x_test_cbow = average_word_vectors(x_test_tok, w2v_cbow)\n",
        "vectorized_data['Word2Vec_CBOW'] = (x_train_cbow, x_test_cbow)\n",
        "\n",
        "x_train_skip = average_word_vectors(x_train_tok, w2v_skipgram)\n",
        "x_test_skip = average_word_vectors(x_test_tok, w2v_skipgram)\n",
        "vectorized_data['Word2Vec_Skipgram'] = (x_train_skip, x_test_skip)\n",
        "\n",
        "x_train_glove = average_word_vectors(x_train_tok, glove)\n",
        "x_test_glove = average_word_vectors(x_test_tok, glove)\n",
        "vectorized_data['GloVe'] = (x_train_glove, x_test_glove)\n",
        "\n",
        "x_train_fast = average_word_vectors(x_train_tok, fasttext)\n",
        "x_test_fast = average_word_vectors(x_test_tok, fasttext)\n",
        "vectorized_data['FastText'] = (x_train_fast, x_test_fast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1wL7ywilNPq",
        "outputId": "3a2f53e8-2246-40cf-9431-f261bbf08533"
      },
      "id": "D1wL7ywilNPq",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectorized_data(vectorizer_type):\n",
        "    if vectorizer_type == 'BoW':\n",
        "        return vectorized_data['BoW']\n",
        "    elif vectorizer_type == 'TF-IDF':\n",
        "        return vectorized_data['TF-IDF']\n",
        "    elif vectorizer_type == 'Word2Vec_CBOW':\n",
        "        return vectorized_data['Word2Vec_CBOW']\n",
        "    elif vectorizer_type == 'Word2Vec_Skipgram':\n",
        "        return vectorized_data['Word2Vec_Skipgram']\n",
        "    elif vectorizer_type == 'GloVe':\n",
        "        return vectorized_data['GloVe']\n",
        "    elif vectorizer_type == 'FastText':\n",
        "        return vectorized_data['FastText']\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown vectorizer type: {vectorizer_type}\")"
      ],
      "metadata": {
        "id": "MsgHayjjlOdZ"
      },
      "id": "MsgHayjjlOdZ",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_mean(embeddings_list, model, dim=300):\n",
        "    vectors = []\n",
        "    for tokens in embeddings_list:\n",
        "        vecs = [model[word] for word in tokens if word in model]\n",
        "        if vecs:\n",
        "            vectors.append(np.mean(vecs, axis=0))\n",
        "        else:\n",
        "            vectors.append(np.zeros(dim))\n",
        "    return np.array(vectors)\n",
        "\n",
        "def combine_max(embeddings_list, model, dim=300):\n",
        "    vectors = []\n",
        "    for tokens in embeddings_list:\n",
        "        vecs = [model[word] for word in tokens if word in model]\n",
        "        if vecs:\n",
        "            vectors.append(np.max(vecs, axis=0))\n",
        "        else:\n",
        "            vectors.append(np.zeros(dim))\n",
        "    return np.array(vectors)\n",
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=300, hidden_dim=128):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        return hn.squeeze(0)\n",
        "\n",
        "def pad_sequences_token_vectors(token_lists, model, dim=300, max_len=40):\n",
        "    padded = []\n",
        "    for tokens in token_lists:\n",
        "        vecs = [model[word] for word in tokens if word in model]\n",
        "        if not vecs:\n",
        "            vecs = [np.zeros(dim)]\n",
        "        if len(vecs) > max_len:\n",
        "            vecs = vecs[:max_len]\n",
        "        else:\n",
        "            vecs += [np.zeros(dim)] * (max_len - len(vecs))\n",
        "        padded.append(vecs)\n",
        "    return torch.tensor(padded, dtype=torch.float32)\n",
        "\n",
        "def combine_lstm(embeddings_list, model, dim=300, max_len=40, batch_size=128):\n",
        "    lstm_model = LSTMEncoder(input_dim=dim)\n",
        "    lstm_model.eval()\n",
        "\n",
        "    data_tensor = pad_sequences_token_vectors(embeddings_list, model, dim, max_len)\n",
        "    loader = DataLoader(data_tensor, batch_size=batch_size)\n",
        "\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            encoded = lstm_model(batch)\n",
        "            outputs.append(encoded)\n",
        "    return torch.cat(outputs).numpy()"
      ],
      "metadata": {
        "id": "mi6RbUYjqmJc"
      },
      "id": "mi6RbUYjqmJc",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_combined_vectors(method, token_list, model, dim=300):\n",
        "    if method == 'mean':\n",
        "        return combine_mean(token_list, model, dim)\n",
        "    elif method == 'max':\n",
        "        return combine_max(token_list, model, dim)\n",
        "    elif method == 'lstm':\n",
        "        return combine_lstm(token_list, model, dim)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown combiner method: {method}\")"
      ],
      "metadata": {
        "id": "1r8XtmZPrDC-"
      },
      "id": "1r8XtmZPrDC-",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_classifier(x_train_vec, x_test_vec, y_train, y_test, classifier_type):\n",
        "    if classifier_type == 'LogisticRegression':\n",
        "        clf = LogisticRegression(max_iter=300)\n",
        "    elif classifier_type == 'DecisionTree':\n",
        "        clf = DecisionTreeClassifier()\n",
        "    elif classifier_type == 'RandomForest':\n",
        "        clf = RandomForestClassifier(n_estimators=100)\n",
        "    elif classifier_type == 'MLP':\n",
        "        clf = MLPClassifier(hidden_layer_sizes=(128,), max_iter=300)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown classifier type: {classifier_type}\")\n",
        "\n",
        "    clf.fit(x_train_vec, y_train)\n",
        "    y_pred = clf.predict(x_test_vec)\n",
        "    return accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Xv9BRv8arENG"
      },
      "id": "Xv9BRv8arENG",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "def log_result(preprocessing, vectorization, combiner, classifier, accuracy):\n",
        "    results.append({\n",
        "        'Preprocessing': preprocessing,\n",
        "        'Vectorization': vectorization,\n",
        "        'Combiner': combiner,\n",
        "        'Classifier': classifier,\n",
        "        'Accuracy': accuracy\n",
        "    })"
      ],
      "metadata": {
        "id": "pFCC8yS3r86B"
      },
      "id": "pFCC8yS3r86B",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "classifier_types = ['LogisticRegression', 'DecisionTree', 'RandomForest', 'MLP']\n",
        "vectorizer_types = list(vectorized_data.keys())\n",
        "\n",
        "for vec_type in vectorizer_types:\n",
        "    x_train_vec, x_test_vec = get_vectorized_data(vec_type)\n",
        "\n",
        "    if vec_type in ['BoW', 'TF-IDF']:\n",
        "        combiner = 'N/A'\n",
        "    else:\n",
        "        combiner = 'mean'\n",
        "\n",
        "    for clf_type in classifier_types:\n",
        "        acc = train_and_evaluate_classifier(x_train_vec, x_test_vec, y_train, y_test, clf_type)\n",
        "        log_result('lemma', vec_type, combiner, clf_type, acc)\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.sort_values(\"Accuracy\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEyJhZjhryv4",
        "outputId": "574f05b6-50d0-451e-81e3-0516499f802f"
      },
      "id": "XEyJhZjhryv4",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Preprocessing      Vectorization Combiner          Classifier  Accuracy\n",
            "0          lemma             TF-IDF      N/A  LogisticRegression     0.754\n",
            "1          lemma                BoW      N/A  LogisticRegression     0.752\n",
            "2          lemma                BoW      N/A                 MLP     0.726\n",
            "3          lemma             TF-IDF      N/A        RandomForest     0.722\n",
            "4          lemma           FastText     mean                 MLP     0.722\n",
            "5          lemma             TF-IDF      N/A        DecisionTree     0.720\n",
            "6          lemma                BoW      N/A        DecisionTree     0.718\n",
            "7          lemma                BoW      N/A        RandomForest     0.704\n",
            "8          lemma             TF-IDF      N/A                 MLP     0.704\n",
            "9          lemma           FastText     mean  LogisticRegression     0.676\n",
            "10         lemma      Word2Vec_CBOW     mean                 MLP     0.672\n",
            "11         lemma              GloVe     mean                 MLP     0.670\n",
            "12         lemma           FastText     mean        RandomForest     0.660\n",
            "13         lemma      Word2Vec_CBOW     mean  LogisticRegression     0.648\n",
            "14         lemma      Word2Vec_CBOW     mean        RandomForest     0.638\n",
            "15         lemma              GloVe     mean        RandomForest     0.638\n",
            "16         lemma              GloVe     mean  LogisticRegression     0.612\n",
            "17         lemma              GloVe     mean        DecisionTree     0.382\n",
            "18         lemma           FastText     mean        DecisionTree     0.356\n",
            "19         lemma      Word2Vec_CBOW     mean        DecisionTree     0.314\n",
            "20         lemma  Word2Vec_Skipgram     mean                 MLP     0.188\n",
            "21         lemma  Word2Vec_Skipgram     mean        RandomForest     0.188\n",
            "22         lemma  Word2Vec_Skipgram     mean        DecisionTree     0.188\n",
            "23         lemma  Word2Vec_Skipgram     mean  LogisticRegression     0.188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}