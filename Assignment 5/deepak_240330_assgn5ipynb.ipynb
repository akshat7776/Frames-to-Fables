{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **CLIP and BLIP MODEL**"
      ],
      "metadata": {
        "id": "jUeTRZYzwBb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYJJhprImfED",
        "outputId": "07b9b62a-8642-4637-d595-b056dee02386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision tqdm pillow transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "3vINMRTgmrB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "CDNmHK1xmrET",
        "outputId": "2bd0750f-22bc-4675-b77e-93076618bca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4db0a413-4a62-473d-b74c-5d0e2e703441\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4db0a413-4a62-473d-b74c-5d0e2e703441\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Assignment 5.zip to Assignment 5 (1).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"Assignment 5.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"images_folder\")\n"
      ],
      "metadata": {
        "id": "pQQjNWo4sgvX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "image_folder = \"images_folder/Assignment 5/images_updated\"\n",
        "\n",
        "image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "image_embeddings = []\n",
        "images = []\n",
        "\n",
        "for path in tqdm(image_paths):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    images.append(img)\n",
        "\n",
        "    inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        embedding = model.get_image_features(**inputs)\n",
        "        embedding = embedding / embedding.norm(p=2, dim=-1, keepdim=True)\n",
        "\n",
        "    image_embeddings.append(embedding.cpu().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdYER9E9sgy3",
        "outputId": "f601359e-66d9-4e9c-a696-63514155a9fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "questions_path = \"images_folder/Assignment 5/filtered_questions.json\"\n",
        "\n",
        "\n",
        "with open(questions_path, 'r') as f:\n",
        "    questions = json.load(f)\n",
        "\n",
        "query = str(questions[2])  # input index\n",
        "\n",
        "print(f\"Selected Query: {query}\")\n",
        "\n",
        "inputs = processor(text=query, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    text_embedding = model.get_text_features(**inputs)\n",
        "    text_embedding = text_embedding / text_embedding.norm(p=2, dim=-1, keepdim=True)\n",
        "text_embedding = text_embedding.cpu().numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "EVKoN19SmrMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25da9662-5fd4-4910-8ce8-3c3bea78e305"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Query: ['does the image contain a rectangle?', 'yes', 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_folder = \"images_folder/Assignment 5/images_updated\"\n",
        "\n",
        "image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "print(f\"Total images found: {len(image_paths)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UzRN_cvdRr",
        "outputId": "9b7d838e-70e2-4dc6-854d-0519f0b4a7a3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 10\n",
            "['images_folder/Assignment 5/images_updated/8.png', 'images_folder/Assignment 5/images_updated/7.png', 'images_folder/Assignment 5/images_updated/3.png', 'images_folder/Assignment 5/images_updated/0.png', 'images_folder/Assignment 5/images_updated/5.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_embeddings = []\n",
        "images = []\n",
        "\n",
        "for path in image_paths:\n",
        "    try:\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        images.append(img)\n",
        "\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedding = model.get_image_features(**inputs)\n",
        "            embedding = embedding / embedding.norm(p=2, dim=-1, keepdim=True)\n",
        "\n",
        "        image_embeddings.append(embedding.cpu().numpy())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {path}: {e}\")\n",
        "\n",
        "print(f\"\\nTotal successfully processed images: {len(image_embeddings)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFTrxhXBvyVy",
        "outputId": "37af4a59-ba77-4ee1-d9d0-6b8d200812c5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total successfully processed images: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = []\n",
        "\n",
        "for emb in image_embeddings:\n",
        "  print(emb.shape, text_embedding.shape)\n",
        "  sim = np.dot(text_embedding, emb.T)\n",
        "  similarities.append(sim.item())\n",
        "\n",
        "best_idx = np.argmax(similarities)\n",
        "\n",
        "plt.imshow(images[best_idx])\n",
        "plt.axis('off')\n",
        "plt.title(f\"Best match for: {query}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QJ2Rci1mmrPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "d874edfa-7cb8-42a4-fd5a-fcb35af8bd38"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n",
            "(1, 512) (1, 512)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total image embeddings: {len(image_embeddings)}\")\n",
        "print(f\"Text embedding shape: {text_embedding.shape}\")\n",
        "\n",
        "for emb in image_embeddings:\n",
        "    print(emb.shape)"
      ],
      "metadata": {
        "id": "b9nX0woWmrR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79a74dd-2faf-451e-e094-c246513671cd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total image embeddings: 10\n",
            "Text embedding shape: (1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n",
            "(1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qAfQSqwwmrUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BLIP MODEL**"
      ],
      "metadata": {
        "id": "HrpBvncXwIk-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omV7XndZmrXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OvtgnciemraC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDHJRBW4mrdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kUpg27jsmrfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2MfA66Smric"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}